{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-15T14:59:03.224997800Z",
     "start_time": "2023-11-15T14:59:03.217128900Z"
    }
   },
   "outputs": [],
   "source": [
    "## Initialize\n",
    "\n",
    "apiKey = \"hTLGygty2Sj5IB368rcArA63Xu29hW2r\"\n",
    "archiveUrl = f\"https://api.nytimes.com/svc/archive/v1/#1/#2.json?api-key={apiKey}\"\n",
    "\n",
    "# Example text\n",
    "text = \"German Chancellor Angela Merkel died in 1936 in New York. She got shot by a mysterious terrorist, terror, terrorism\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-15T14:59:09.457025300Z",
     "start_time": "2023-11-15T14:59:03.823916500Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://api.nytimes.com/svc/archive/v1/1963/10.json?api-key=hTLGygty2Sj5IB368rcArA63Xu29hW2r\n"
     ]
    }
   ],
   "source": [
    "## Fetch\n",
    "import requests\n",
    "import json\n",
    "\n",
    "year = 1963\n",
    "month = 10\n",
    "\n",
    "requestUrl = archiveUrl.replace(\"#1\", f\"{year}\").replace(\"#2\", f\"{month}\")\n",
    "print(requestUrl)\n",
    "res = requests.get(requestUrl)\n",
    "obj = json.loads(res.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-15T15:01:44.657036800Z",
     "start_time": "2023-11-15T14:59:09.459531200Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "94c945a8d6264225a886196f0f40664b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Going through articles:   0%|          | 0/11585 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## Search\n",
    "from multiprocessing import Pool, Manager\n",
    "from tqdm.notebook import tqdm\n",
    "from utils import parseArticle\n",
    "\n",
    "docs = obj[\"response\"][\"docs\"]\n",
    "\n",
    "# https://stackoverflow.com/questions/5549190/is-shared-readonly-data-copied-to-different-processes-for-multiprocessing/5550156#5550156\n",
    "# https://docs.python.org/3/library/multiprocessing.shared_memory.html\n",
    "# python feed pool with shared memory\n",
    "# https://stackoverflow.com/questions/77502344/how-do-shareablelists-actually-work-when-multiprocessing-in-python\n",
    "\n",
    "articleWordCount = []\n",
    "# Brudi das zerstört meinen RAM komplett\n",
    "with Manager() as smm:\n",
    "    sl = smm.list()\n",
    "    sl.extend(docs)\n",
    "    with Pool(processes=3) as p:\n",
    "        with tqdm(total=len(sl), desc=\"Going through articles\") as pbar:\n",
    "            for res in p.imap_unordered(parseArticle, sl, chunksize=10):\n",
    "                articleWordCount.append(res)\n",
    "                pbar.update()\n",
    "            # Use this to test topic fill\n",
    "            #for res in p.imap_unordered(utils.test, docs):\n",
    "            #    print(res)\n",
    "            #    pbar.update() \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Save results for testing\n",
    "\n",
    "#with open(\"./testfiles/articles.json\", \"w\", encoding=\"utf-8\") as json_file:\n",
    "#    json_file.write(json.dumps(obj, indent=\"\\t\"))\n",
    "with open(f\"./testfiles/result_{year}_{month}.json\", \"w\", encoding=\"utf-8\") as json_file:\n",
    "    json_file.write(json.dumps(articleWordCount, indent=\"\\t\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      " [2. 2. 2. 2. 2. 2. 2. 2. 2. 2.]\n",
      " [3. 3. 3. 3. 3. 3. 3. 3. 3. 3.]\n",
      " [4. 4. 4. 4. 4. 4. 4. 4. 4. 4.]\n",
      " [5. 5. 5. 5. 5. 5. 5. 5. 5. 5.]\n",
      " [6. 6. 6. 6. 6. 6. 6. 6. 6. 6.]\n",
      " [7. 7. 7. 7. 7. 7. 7. 7. 7. 7.]\n",
      " [8. 8. 8. 8. 8. 8. 8. 8. 8. 8.]\n",
      " [9. 9. 9. 9. 9. 9. 9. 9. 9. 9.]]\n"
     ]
    }
   ],
   "source": [
    "# wtff\n",
    "import multiprocessing\n",
    "from tqdm.notebook import tqdm\n",
    "import ctypes\n",
    "import numpy as np\n",
    "from utils import init, my_func\n",
    "\n",
    "#-- edited 2015-05-01: the assert check below checks the wrong thing\n",
    "#   with recent versions of Numpy/multiprocessing. That no copy is made\n",
    "#   is indicated by the fact that the program prints the output shown below.\n",
    "## No copy was made\n",
    "##assert shared_array.base.base is shared_array_base.get_obj()\n",
    "l = []\n",
    "for i in range(10):\n",
    "    l.append({\"a\": i, \"b\": {\"c\": i**2}})\n",
    "    \n",
    "shared_array_base = multiprocessing.Array(l)\n",
    "docs = range(10)\n",
    "with multiprocessing.Pool(processes=3, initializer=init, initargs=(shared_array_base,)) as p:\n",
    "    with tqdm(total=len(docs), desc=\"Going through articles\") as pbar:\n",
    "        for res in p.imap_unordered(my_func, docs):\n",
    "            pbar.update()\n",
    "\n",
    "shared_array = np.ctypeslib.as_array(shared_array_base.get_obj())\n",
    "shared_array = shared_array.reshape(10, 10)\n",
    "print(shared_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-22T21:29:28.664255700Z",
     "start_time": "2023-11-22T21:28:20.091585Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'a': 0, 'b': {'c': 0}}, {'a': 1, 'b': {'c': 1}}, {'a': 2, 'b': {'c': 4}}, {'a': 3, 'b': {'c': 9}}, {'a': 4, 'b': {'c': 16}}, {'a': 5, 'b': {'c': 25}}, {'a': 6, 'b': {'c': 36}}, {'a': 7, 'b': {'c': 49}}, {'a': 8, 'b': {'c': 64}}, {'a': 9, 'b': {'c': 81}}]\n",
      "[{'a': 0, 'b': {'c': 0}}, {'a': 1, 'b': {'c': 1}}, {'a': 2, 'b': {'c': 4}}, {'a': 3, 'b': {'c': 9}}, {'a': 4, 'b': {'c': 16}}, {'a': 5, 'b': {'c': 25}}, {'a': 6, 'b': {'c': 36}}, {'a': 7, 'b': {'c': 49}}, {'a': 8, 'b': {'c': 64}}, {'a': 9, 'b': {'c': 81}}]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "24364c08df1d4a739d176dc3f3433a50",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Going through articles:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "why? {'a': 2, 'b': {'c': 4}}, []\n",
      "why? {'a': 1, 'b': {'c': 1}}, []\n",
      "why? {'a': 0, 'b': {'c': 0}}, []\n",
      "why? {'a': 3, 'b': {'c': 9}}, []\n",
      "why? {'a': 4, 'b': {'c': 16}}, []\n",
      "why? {'a': 5, 'b': {'c': 25}}, []\n",
      "why? {'a': 6, 'b': {'c': 36}}, []\n",
      "why? {'a': 7, 'b': {'c': 49}}, []\n",
      "why? {'a': 8, 'b': {'c': 64}}, []\n",
      "why? {'a': 9, 'b': {'c': 81}}, []\n"
     ]
    }
   ],
   "source": [
    "# Test shared mem\n",
    "from multiprocessing import Pool, Manager\n",
    "from multiprocessing.shared_memory import SharedMemory\n",
    "from tqdm.notebook import tqdm\n",
    "from utils import *\n",
    "\n",
    "l = []\n",
    "for i in range(10):\n",
    "    l.append({\"a\": i, \"b\": {\"c\": i**2}})\n",
    "\n",
    "with Manager() as smm:\n",
    "    sl = smm.list()\n",
    "    sl.extend(l)\n",
    "    print(setArr(l))\n",
    "    print(getArr())\n",
    "    with Pool(processes=3) as p:\n",
    "        with tqdm(total=len(sl), desc=\"Going through articles\") as pbar:\n",
    "            for res in p.imap_unordered(mult, sl, chunksize=1):\n",
    "                print(res)\n",
    "                pbar.update()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#There to compare different results of words\n",
    "def getWords(article):\n",
    "    return list(article[\"wordCount\"].keys())\n",
    "def flat(ll):\n",
    "    ret = []\n",
    "    for l in ll:\n",
    "        ret.extend(l)\n",
    "    return list(set(ret))\n",
    "\n",
    "words = flat(list(map(lambda a: getWords(a), articleWordCount)))\n",
    "words = sorted(words)\n",
    "with open(\"./testfiles/result2.json\", \"w\", encoding=\"utf-8\") as json_file:\n",
    "    json_file.write(json.dumps(words, indent=\"\\t\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-11-05T18:59:35.127179Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------Taggers----------\n",
      "$: symbol, currency\n",
      "'': closing quotation mark\n",
      ",: punctuation mark, comma\n",
      "-LRB-: left round bracket\n",
      "-RRB-: right round bracket\n",
      ".: punctuation mark, sentence closer\n",
      ":: punctuation mark, colon or ellipsis\n",
      "ADD: email\n",
      "AFX: affix\n",
      "CC: conjunction, coordinating\n",
      "CD: cardinal number\n",
      "DT: determiner\n",
      "EX: existential there\n",
      "FW: foreign word\n",
      "HYPH: punctuation mark, hyphen\n",
      "IN: conjunction, subordinating or preposition\n",
      "JJ: adjective (English), other noun-modifier (Chinese)\n",
      "JJR: adjective, comparative\n",
      "JJS: adjective, superlative\n",
      "LS: list item marker\n",
      "MD: verb, modal auxiliary\n",
      "NFP: superfluous punctuation\n",
      "NN: noun, singular or mass\n",
      "NNP: noun, proper singular\n",
      "NNPS: noun, proper plural\n",
      "NNS: noun, plural\n",
      "PDT: predeterminer\n",
      "POS: possessive ending\n",
      "PRP: pronoun, personal\n",
      "PRP$: pronoun, possessive\n",
      "RB: adverb\n",
      "RBR: adverb, comparative\n",
      "RBS: adverb, superlative\n",
      "RP: adverb, particle\n",
      "SYM: symbol\n",
      "TO: infinitival \"to\"\n",
      "UH: interjection\n",
      "VB: verb, base form\n",
      "VBD: verb, past tense\n",
      "VBG: verb, gerund or present participle\n",
      "VBN: verb, past participle\n",
      "VBP: verb, non-3rd person singular present\n",
      "VBZ: verb, 3rd person singular present\n",
      "WDT: wh-determiner\n",
      "WP: wh-pronoun, personal\n",
      "WP$: wh-pronoun, possessive\n",
      "WRB: wh-adverb\n",
      "XX: unknown\n",
      "_SP: whitespace\n",
      "``: opening quotation mark\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "taggers = [{\n",
    "    \"name\": \"Taggers\",\n",
    "    \"values\": [\n",
    "        \"$\", \"''\", \",\", \"-LRB-\", \"-RRB-\", \".\", \":\", \"ADD\", \"AFX\", \"CC\", \"CD\", \"DT\", \"EX\", \"FW\", \"HYPH\", \"IN\", \"JJ\", \"JJR\", \"JJS\", \"LS\", \"MD\", \"NFP\", \"NN\", \"NNP\", \"NNPS\", \"NNS\", \"PDT\", \"POS\", \"PRP\", \"PRP$\", \"RB\", \"RBR\", \"RBS\", \"RP\", \"SYM\", \"TO\", \"UH\", \"VB\", \"VBD\", \"VBG\", \"VBN\", \"VBP\", \"VBZ\", \"WDT\", \"WP\", \"WP$\", \"WRB\", \"XX\", \"_SP\", \"``\"\n",
    "    ]\n",
    "}]\n",
    "\n",
    "for tagger in taggers:\n",
    "    print(f\"---------{tagger['name']}----------\")\n",
    "    for tag in tagger[\"values\"]:\n",
    "        print(f\"{tag}: {spacy.explain(tag)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "German Chancellor Angela Merkel died in 1936 in New York. She got shot by a mysterious terrorist, terror, terrorism\n",
      "German, PROPN, False, False\n",
      "Chancellor, PROPN, False, False\n",
      "Angela Merkel, PROPN, False, False\n",
      "die, VERB, False, False\n",
      "in, ADP, True, False\n",
      "1936, NUM, False, False\n",
      "in, ADP, True, False\n",
      "New York, PROPN, False, False\n",
      "., PUNCT, False, True\n",
      "she, PRON, True, False\n",
      "get, VERB, False, False\n",
      "shoot, VERB, False, False\n",
      "by, ADP, True, False\n",
      "a, DET, True, False\n",
      "mysterious, ADJ, False, False\n",
      "terrorist, NOUN, False, False\n",
      ",, PUNCT, False, True\n",
      "terror, NOUN, False, False\n",
      ",, PUNCT, False, True\n",
      "terrorism, NOUN, False, False\n"
     ]
    }
   ],
   "source": [
    "import utils\n",
    "\n",
    "t = \"I ate food grasiously. He has eaten. She eats. They eat\\nThere was terror. Terrorism is bad. There were terrorists.\"\n",
    "lemmas = utils.get(text)\n",
    "print(lemmas)\n",
    "for l in lemmas:\n",
    "    print(f\"{l.lemma_}, {l.pos_}, {l.is_stop}, {l.is_punct}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-22T21:42:16.894837100Z",
     "start_time": "2023-11-22T21:40:52.784772900Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "62618f18a8af40009ec981e838d7d69f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Going through months:   0%|          | 0/432 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current: 1964/1\n",
      "https://api.nytimes.com/svc/archive/v1/1964/1.json?api-key=hTLGygty2Sj5IB368rcArA63Xu29hW2r\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0c5bf5b48e13429094a65369047399cb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Going through articles:   0%|          | 0/12273 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current: 1964/2\n",
      "https://api.nytimes.com/svc/archive/v1/1964/2.json?api-key=hTLGygty2Sj5IB368rcArA63Xu29hW2r\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9ad61483585c4f8db6fbf1c60a24e712",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Going through articles:   0%|          | 0/10739 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current: 1964/3\n",
      "https://api.nytimes.com/svc/archive/v1/1964/3.json?api-key=hTLGygty2Sj5IB368rcArA63Xu29hW2r\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "53dc16f004e446458eecf96f312d8269",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Going through articles:   0%|          | 0/11877 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current: 1964/4\n",
      "https://api.nytimes.com/svc/archive/v1/1964/4.json?api-key=hTLGygty2Sj5IB368rcArA63Xu29hW2r\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4ad4b80ee7324033b002273f24076c7d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Going through articles:   0%|          | 0/11460 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\multiprocessing\\pool.py:856\u001b[0m, in \u001b[0;36mIMapIterator.next\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    855\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 856\u001b[0m     item \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_items\u001b[39m.\u001b[39mpopleft()\n\u001b[0;32m    857\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mIndexError\u001b[39;00m:\n",
      "\u001b[1;31mIndexError\u001b[0m: pop from an empty deque",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\sean_\\OneDrive\\Dokumente\\Studium\\Big Data\\UdosWordCloud\\Scraper\\udo-cluster.ipynb Cell 11\u001b[0m line \u001b[0;36m7\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/sean_/OneDrive/Dokumente/Studium/Big%20Data/UdosWordCloud/Scraper/udo-cluster.ipynb#X23sZmlsZQ%3D%3D?line=72'>73</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mcurrent: \u001b[39m\u001b[39m{\u001b[39;00myear\u001b[39m}\u001b[39;00m\u001b[39m/\u001b[39m\u001b[39m{\u001b[39;00mmonth\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/sean_/OneDrive/Dokumente/Studium/Big%20Data/UdosWordCloud/Scraper/udo-cluster.ipynb#X23sZmlsZQ%3D%3D?line=73'>74</a>\u001b[0m docs \u001b[39m=\u001b[39m getDocs(year, month)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/sean_/OneDrive/Dokumente/Studium/Big%20Data/UdosWordCloud/Scraper/udo-cluster.ipynb#X23sZmlsZQ%3D%3D?line=74'>75</a>\u001b[0m wordCount \u001b[39m=\u001b[39m getWordCount(docs)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/sean_/OneDrive/Dokumente/Studium/Big%20Data/UdosWordCloud/Scraper/udo-cluster.ipynb#X23sZmlsZQ%3D%3D?line=75'>76</a>\u001b[0m saveWordCount(wordCount, year, month)\n",
      "\u001b[1;32mc:\\Users\\sean_\\OneDrive\\Dokumente\\Studium\\Big Data\\UdosWordCloud\\Scraper\\udo-cluster.ipynb Cell 11\u001b[0m line \u001b[0;36m3\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/sean_/OneDrive/Dokumente/Studium/Big%20Data/UdosWordCloud/Scraper/udo-cluster.ipynb#X23sZmlsZQ%3D%3D?line=32'>33</a>\u001b[0m \u001b[39mwith\u001b[39;00m Pool(processes\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m) \u001b[39mas\u001b[39;00m p:\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/sean_/OneDrive/Dokumente/Studium/Big%20Data/UdosWordCloud/Scraper/udo-cluster.ipynb#X23sZmlsZQ%3D%3D?line=33'>34</a>\u001b[0m     \u001b[39mwith\u001b[39;00m tqdm(total\u001b[39m=\u001b[39m\u001b[39mlen\u001b[39m(sl), desc\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mGoing through articles\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mas\u001b[39;00m articlePbar:\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/sean_/OneDrive/Dokumente/Studium/Big%20Data/UdosWordCloud/Scraper/udo-cluster.ipynb#X23sZmlsZQ%3D%3D?line=34'>35</a>\u001b[0m         \u001b[39mfor\u001b[39;49;00m res \u001b[39min\u001b[39;49;00m p\u001b[39m.\u001b[39;49mimap_unordered(parseArticle, sl, chunksize\u001b[39m=\u001b[39;49m\u001b[39m100\u001b[39;49m):\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/sean_/OneDrive/Dokumente/Studium/Big%20Data/UdosWordCloud/Scraper/udo-cluster.ipynb#X23sZmlsZQ%3D%3D?line=35'>36</a>\u001b[0m             articleWordCount\u001b[39m.\u001b[39;49mappend(res)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/sean_/OneDrive/Dokumente/Studium/Big%20Data/UdosWordCloud/Scraper/udo-cluster.ipynb#X23sZmlsZQ%3D%3D?line=36'>37</a>\u001b[0m             articlePbar\u001b[39m.\u001b[39;49mupdate()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\multiprocessing\\pool.py:451\u001b[0m, in \u001b[0;36m<genexpr>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    443\u001b[0m result \u001b[39m=\u001b[39m IMapUnorderedIterator(\u001b[39mself\u001b[39m)\n\u001b[0;32m    444\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_taskqueue\u001b[39m.\u001b[39mput(\n\u001b[0;32m    445\u001b[0m     (\n\u001b[0;32m    446\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_guarded_task_generation(result\u001b[39m.\u001b[39m_job,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    449\u001b[0m         result\u001b[39m.\u001b[39m_set_length\n\u001b[0;32m    450\u001b[0m     ))\n\u001b[1;32m--> 451\u001b[0m \u001b[39mreturn\u001b[39;00m (item \u001b[39mfor\u001b[39;49;00m chunk \u001b[39min\u001b[39;49;00m result \u001b[39mfor\u001b[39;49;00m item \u001b[39min\u001b[39;49;00m chunk)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\multiprocessing\\pool.py:861\u001b[0m, in \u001b[0;36mIMapIterator.next\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    859\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pool \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    860\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mStopIteration\u001b[39;00m \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m--> 861\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_cond\u001b[39m.\u001b[39;49mwait(timeout)\n\u001b[0;32m    862\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m    863\u001b[0m     item \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_items\u001b[39m.\u001b[39mpopleft()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\threading.py:320\u001b[0m, in \u001b[0;36mCondition.wait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    318\u001b[0m \u001b[39mtry\u001b[39;00m:    \u001b[39m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[39;00m\n\u001b[0;32m    319\u001b[0m     \u001b[39mif\u001b[39;00m timeout \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 320\u001b[0m         waiter\u001b[39m.\u001b[39;49macquire()\n\u001b[0;32m    321\u001b[0m         gotit \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[0;32m    322\u001b[0m     \u001b[39melse\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import os\n",
    "import requests\n",
    "import json\n",
    "from multiprocessing import Pool, Manager\n",
    "from tqdm.notebook import tqdm\n",
    "from utils import parseArticle\n",
    "\n",
    "## Initialize\n",
    "\n",
    "apiKey = \"hTLGygty2Sj5IB368rcArA63Xu29hW2r\"\n",
    "archiveUrl = f\"https://api.nytimes.com/svc/archive/v1/#1/#2.json?api-key={apiKey}\"\n",
    "\n",
    "\n",
    "def getDocs(year, month):\n",
    "    requestUrl = archiveUrl.replace(\"#1\", f\"{year}\").replace(\"#2\", f\"{month}\")\n",
    "    print(requestUrl)\n",
    "    res = requests.get(requestUrl)\n",
    "    return json.loads(res.text)[\"response\"][\"docs\"]\n",
    "\n",
    "\n",
    "## Search\n",
    "\n",
    "# https://stackoverflow.com/questions/5549190/is-shared-readonly-data-copied-to-different-processes-for-multiprocessing/5550156#5550156\n",
    "# https://docs.python.org/3/library/multiprocessing.shared_memory.html\n",
    "# python feed pool with shared memory\n",
    "# https://stackoverflow.com/questions/77502344/how-do-shareablelists-actually-work-when-multiprocessing-in-python\n",
    "def getWordCount(docs):\n",
    "    articleWordCount = []\n",
    "    # Brudi das zerstört meinen RAM komplett\n",
    "    with Manager() as smm:\n",
    "        sl = smm.list()\n",
    "        sl.extend(docs)\n",
    "        with Pool(processes=2) as p:\n",
    "            with tqdm(total=len(sl), desc=\"Going through articles\") as articlePbar:\n",
    "                for res in p.imap_unordered(parseArticle, sl, chunksize=10):\n",
    "                    articleWordCount.append(res)\n",
    "                    articlePbar.update()\n",
    "                # Use this to test topic fill\n",
    "                # for res in p.imap_unordered(utils.test, docs):\n",
    "                #    print(res)\n",
    "                #    pbar.update()\n",
    "    return articleWordCount\n",
    "\n",
    "\n",
    "## Save results for testing\n",
    "\n",
    "# with open(\"./testfiles/articles.json\", \"w\", encoding=\"utf-8\") as json_file:\n",
    "#    json_file.write(json.dumps(obj, indent=\"\\t\"))\n",
    "def saveWordCount(articleWordCount, year, month):\n",
    "    with open(f\"./resultfiles/result_{year}_{month}.json\", \"w\", encoding=\"utf-8\") as json_file:\n",
    "        json_file.write(json.dumps(articleWordCount, indent=\"\\t\"))\n",
    "\n",
    "\n",
    "## Fetch\n",
    "\n",
    "year_min = 1964\n",
    "year_max = 2000\n",
    "month_min = 1\n",
    "month_max = 13\n",
    "with tqdm(total=((year_max - year_min) * 12), desc=\"Going through months\", maxinterval=1) as pbar:\n",
    "    for month in range(1, month_min):\n",
    "        os.system('cls')\n",
    "        pbar.display()\n",
    "        print(f\"current: {year_min}/{month}\")\n",
    "        docs = getDocs(year, month)\n",
    "        wordCount = getWordCount(docs)\n",
    "        saveWordCount(wordCount, year, month)\n",
    "        pbar.update()\n",
    "\n",
    "    for year in range(year_min, year_max):\n",
    "        for month in range(month_min, month_max):\n",
    "            os.system('cls')\n",
    "            pbar.display()\n",
    "            print(f\"current: {year}/{month}\")\n",
    "            docs = getDocs(year, month)\n",
    "            wordCount = getWordCount(docs)\n",
    "            saveWordCount(wordCount, year, month)\n",
    "            pbar.update()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "UdoScraper",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
